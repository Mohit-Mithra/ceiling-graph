{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graphmem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohit-Mithra/ceiling-graph/blob/main/graphmem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U31K_Bgx60jC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e746a3-9f52-428f-e431-f909ed797f4e"
      },
      "source": [
        "\n",
        "afrom google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pwd\n",
        "%cd drive/My Drive/ceiling-graphs/TGN_ablation/TGN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "/content/drive/My Drive/ceiling-graphs/TGN_ablation/TGN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KLJmP1OsqnG",
        "outputId": "212d2a1b-2be9-4497-a906-a52c41b3e5eb"
      },
      "source": [
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "!python -c \"import torch; print(torch.__version__)\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.1\n",
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAIfRD5Hs2zg"
      },
      "source": [
        "%%capture\n",
        "!pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!!pip install git+https://github.com/rusty1s/pytorch_geometric.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzHmwxfRtIlS"
      },
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "from torch.nn import Linear, LSTM\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score\n",
        "\n",
        "from torch_geometric.datasets import JODIEDataset\n",
        "from torch_geometric.nn import TGNMemory, TransformerConv\n",
        "from torch_geometric.nn.models.tgn import (LastNeighborLoader, IdentityMessage, LastAggregator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRFX-QbhlKI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df656f0f-9a47-4e3e-8d9b-0d5b1ee2e160"
      },
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import pandas\n",
        "from torch_geometric.data import InMemoryDataset, TemporalData, download_url\n",
        "\n",
        "class genericDataset(InMemoryDataset):\n",
        "\n",
        "    def __init__(self, root, name, transform=None, pre_transform=None):\n",
        "        self.name = name.lower()\n",
        "        assert self.name == 'random'\n",
        "\n",
        "        super(genericDataset, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_dir(self):\n",
        "        return osp.join(self.root, self.name, 'raw')\n",
        "\n",
        "    @property\n",
        "    def processed_dir(self):\n",
        "        return osp.join(self.root, self.name, 'processed')\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return f'{self.name}.csv'\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'data.pt'\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        df = pandas.read_csv(self.raw_paths[0], skiprows=1, header=None)\n",
        "\n",
        "        src = torch.from_numpy(df.iloc[:, 0].values).to(torch.long)\n",
        "        dst = torch.from_numpy(df.iloc[:, 1].values).to(torch.long)\n",
        "        dst += int(src.max()) + 1\n",
        "        t = torch.from_numpy(df.iloc[:, 2].values).to(torch.long)\n",
        "        y = torch.from_numpy(df.iloc[:, 3].values).to(torch.long)\n",
        "        msg = torch.from_numpy(df.iloc[:, 4:].values).to(torch.float)\n",
        "\n",
        "        data = TemporalData(src=src, dst=dst, t=t, msg=msg, y=y)\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data = self.pre_transform(data)\n",
        "\n",
        "        torch.save(self.collate([data]), self.processed_paths[0])\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.name.capitalize()}()'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "path = osp.join('..', 'data', 'JODIE')\n",
        "dataset = genericDataset(path, name='random')\n",
        "data = dataset[0].to(device)\n",
        "\n",
        "# Ensure to only sample actual destination nodes as negatives.\n",
        "min_dst_idx, max_dst_idx = int(data.dst.min()), int(data.dst.max())\n",
        "\n",
        "train_data, val_data, test_data = data.train_val_test_split(\n",
        "    val_ratio=0.15, test_ratio=0.15)\n",
        "\n",
        "neighbor_loader = LastNeighborLoader(data.num_nodes, size=10, device=device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaDhC0v8ZTDF"
      },
      "source": [
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# path = osp.join('..', 'data', 'JODIE')\n",
        "# dataset = JODIEDataset(path, name='wikipedia')\n",
        "# data = dataset[0].to(device)\n",
        "\n",
        "# min_dst_idx, max_dst_idx = int(data.dst.min()), int(data.dst.max())\n",
        "\n",
        "# train_data, val_data, test_data = data.train_val_test_split(\n",
        "#     val_ratio=0.15, test_ratio=0.15)\n",
        "\n",
        "# neighbor_loader = LastNeighborLoader(data.num_nodes, size=10, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTI8Zw1H9cBH"
      },
      "source": [
        "from torch_geometric.nn.inits import zeros\n",
        "\n",
        "class global_memory(torch.nn.Module):\n",
        "    def __init__(self, in_channel, global_mem_dimension):\n",
        "        super(global_memory, self).__init__() \n",
        "        self.lin_global1 = Linear(in_channel*2, in_channel*2)\n",
        "        self.lin_global2 = Linear(in_channel*2, global_mem_dimension)\n",
        "\n",
        "    def forward(self, src_embedding, dst_embedding):\n",
        "        inp = torch.cat((src_embedding, dst_embedding), dim=1)\n",
        "        global_embedding = self.lin_global1(inp)\n",
        "        global_embedding = self.lin_global2(global_embedding)\n",
        "        # print('Global embedding shape')\n",
        "        # print(global_embedding.size())\n",
        "        return global_embedding\n",
        "\n",
        "\n",
        "class global_memory_lstm(torch.nn.Module):\n",
        "    def __init__(self, in_channel, hidden_dim, embedding_size):\n",
        "        super(global_memory_lstm, self).__init__() \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.h = torch.zeros(1, 1, hidden_dim).cuda()\n",
        "        self.c = torch.zeros(1, 1, hidden_dim).cuda()\n",
        "        self.lstm_out = torch.zeros(200, 1, hidden_dim).cuda()\n",
        "        self.lstm = LSTM(in_channel*2, hidden_dim)\n",
        "        self.linear = Linear(hidden_dim, embedding_size)\n",
        "\n",
        "    def forward(self, src_embedding, dst_embedding):\n",
        "        inp = torch.cat((src_embedding, dst_embedding), dim=1)\n",
        "        lstm_out, (self.h, self.c) = self.lstm(inp.view(len(inp), 1, -1), (self.h, self.c))\n",
        "        # print(lstm_out.size())\n",
        "        embedding = self.linear(lstm_out.view(len(inp), -1))\n",
        "        return embedding\n",
        "\n",
        "    def reset_state(self):\n",
        "        zeros(self.h)\n",
        "        zeros(self.c)\n",
        "        zeros(self.lstm_out)\n",
        "\n",
        "    def detach(self):\n",
        "        self.h.detach_()\n",
        "        self.c.detach_()\n",
        "        self.lstm_out.detach_()\n",
        "\n",
        "\n",
        "class global_lstmcell(torch.nn.Module):\n",
        "    def __init__(self, in_channel, hidden_dim, embedding_size):\n",
        "        super(global_lstmcell, self).__init__() \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.h = torch.zeros(1, hidden_dim).cuda()\n",
        "        self.gru = torch.nn.GRUCell(in_channel*2, hidden_dim)\n",
        "        self.linear = Linear(hidden_dim, embedding_size)\n",
        "\n",
        "    def forward(self, src_embedding, dst_embedding):\n",
        "        inp = torch.cat((src_embedding, dst_embedding), dim=1)\n",
        "\n",
        "        output = torch.zeros(inp.size()[0], self.hidden_dim).cuda()\n",
        "\n",
        "        for i in range(inp.size()[0]):\n",
        "            self.h = self.gru(inp[i].view(1, -1), self.h)\n",
        "            output[i] = self.h\n",
        "\n",
        "        # print(self.h.size())\n",
        "        embedding = self.linear(output.view(len(inp), -1))\n",
        "        return embedding\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.gru.reset_parameters()\n",
        "        zeros(self.h)    \n",
        "\n",
        "    def detach(self):\n",
        "        self.h.detach_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9i61TYszVCa"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class GraphAttentionEmbedding(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, msg_dim, time_enc):\n",
        "        super(GraphAttentionEmbedding, self).__init__()\n",
        "        self.time_enc = time_enc\n",
        "        edge_dim = msg_dim + time_enc.out_channels\n",
        "        self.conv = TransformerConv(in_channels, out_channels // 2, heads=2,\n",
        "                                    dropout=0.1, edge_dim=edge_dim)\n",
        "\n",
        "    def forward(self, x, last_update, edge_index, t, msg):\n",
        "        rel_t = last_update[edge_index[0]] - t\n",
        "        rel_t_enc = self.time_enc(rel_t.to(x.dtype))\n",
        "        edge_attr = torch.cat([rel_t_enc, msg], dim=-1)\n",
        "        return self.conv(x, edge_index, edge_attr)\n",
        "\n",
        "\n",
        "class LinkPredictor_global(torch.nn.Module):\n",
        "    def __init__(self, in_channels, global_in_channel):\n",
        "        super(LinkPredictor_global, self).__init__()\n",
        "        self.lin_src = Linear(in_channels+global_in_channel, in_channels+global_in_channel)\n",
        "        self.lin_dst = Linear(in_channels+global_in_channel, in_channels+global_in_channel)\n",
        "        self.lin_final = Linear(in_channels+global_in_channel, 1)\n",
        "\n",
        "    def forward(self, z_src, z_dst, z_global):\n",
        "        h = self.lin_src(torch.cat((z_src, z_global), dim=1)) + self.lin_dst(torch.cat((z_dst, z_global), dim=1))\n",
        "        # print(h.size())\n",
        "        h = h.relu()\n",
        "        return self.lin_final(h)\n",
        "\n",
        "class LinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(LinkPredictor, self).__init__()\n",
        "        self.lin_src = Linear(in_channels, in_channels)\n",
        "        self.lin_dst = Linear(in_channels, in_channels)\n",
        "        self.lin_final = Linear(in_channels, 1)\n",
        "\n",
        "    def forward(self, z_src, z_dst):\n",
        "        h = self.lin_src(z_src) + self.lin_dst(z_dst)\n",
        "        h = h.relu()\n",
        "        return self.lin_final(h)\n",
        "\n",
        "\n",
        "memory_dim = time_dim = embedding_dim = 100\n",
        "global_mem_dim = 100\n",
        "hidden_dim = 100\n",
        "\n",
        "memory = TGNMemory(\n",
        "    data.num_nodes,\n",
        "    data.msg.size(-1),\n",
        "    memory_dim,\n",
        "    time_dim,\n",
        "    message_module=IdentityMessage(data.msg.size(-1), memory_dim, time_dim),\n",
        "    aggregator_module=LastAggregator(),\n",
        ").to(device)\n",
        "\n",
        "gnn = GraphAttentionEmbedding(\n",
        "    in_channels=memory_dim,\n",
        "    out_channels=embedding_dim,\n",
        "    msg_dim=data.msg.size(-1),\n",
        "    time_enc=memory.time_enc,\n",
        ").to(device)\n",
        "\n",
        "#global_mem = global_memory(embedding_dim, global_mem_dim).to(device)\n",
        "# global_mem = global_memory_lstm(embedding_dim, global_mem_dim, global_mem_dim).to(device)\n",
        "global_mem = global_lstmcell(embedding_dim, hidden_dim, global_mem_dim).to(device)\n",
        "\n",
        "\n",
        "\n",
        "# link_pred = LinkPredictor(in_channels=embedding_dim).to(device)\n",
        "link_pred = LinkPredictor_global(in_channels=embedding_dim, global_in_channel = global_mem_dim).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    set(memory.parameters()) | set(gnn.parameters()) | set(global_mem.parameters())\n",
        "    | set(link_pred.parameters()), lr=0.0001)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "assoc = torch.empty(data.num_nodes, dtype=torch.long, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxzBopw-1k2f"
      },
      "source": [
        "def train():\n",
        "    memory.train()\n",
        "    gnn.train()\n",
        "    link_pred.train()\n",
        "    global_mem.train()\n",
        "\n",
        "    memory.reset_state()  # Start with a fresh memory.\n",
        "    neighbor_loader.reset_state()  # Start with an empty graph.\n",
        "    global_mem.reset_state() #start with a fresh graph memory\n",
        "\n",
        "    total_loss = 0\n",
        "    total_global_loss = 0\n",
        "    for batch in train_data.seq_batches(batch_size=200):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        src, pos_dst, t, msg = batch.src, batch.dst, batch.t, batch.msg\n",
        "\n",
        "        # Sample negative destination nodes.\n",
        "        neg_dst = torch.randint(min_dst_idx, max_dst_idx + 1, (src.size(0), ),\n",
        "                                dtype=torch.long, device=device)\n",
        "\n",
        "        n_id = torch.cat([src, pos_dst, neg_dst]).unique()\n",
        "        n_id, edge_index, e_id = neighbor_loader(n_id)\n",
        "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
        "\n",
        "        # Get updated memory of all nodes involved in the computation.\n",
        "        z, last_update = memory(n_id)\n",
        "        z = gnn(z, last_update, edge_index, data.t[e_id], data.msg[e_id])\n",
        "\n",
        "        z_global_pos = global_mem(z[assoc[src]], z[assoc[pos_dst]])\n",
        "        z_global_neg = global_mem(z[assoc[src]], z[assoc[neg_dst]])\n",
        "\n",
        "        # pos_out = link_pred(z[assoc[src]], z[assoc[pos_dst]])\n",
        "        # neg_out = link_pred(z[assoc[src]], z[assoc[neg_dst]])\n",
        "\n",
        "        pos_out = link_pred(z[assoc[src]], z[assoc[pos_dst]], z_global_pos)\n",
        "        neg_out = link_pred(z[assoc[src]], z[assoc[neg_dst]], z_global_neg)\n",
        "\n",
        "        loss = criterion(pos_out, torch.ones_like(pos_out))\n",
        "        loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
        "\n",
        "        # Update memory and neighbor loader with ground-truth state.\n",
        "        memory.update_state(src, pos_dst, t, msg)\n",
        "        neighbor_loader.insert(src, pos_dst)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        memory.detach()\n",
        "        global_mem.detach()\n",
        "        \n",
        "        total_loss += float(loss) * batch.num_events\n",
        "    return total_loss / train_data.num_events"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOcF4eRp1pMa"
      },
      "source": [
        "@torch.no_grad()\n",
        "def test(inference_data):\n",
        "    memory.eval()\n",
        "    gnn.eval()\n",
        "    link_pred.eval()\n",
        "    global_mem.eval()\n",
        "\n",
        "    torch.manual_seed(12345)  # Ensure deterministic sampling across epochs.\n",
        "\n",
        "    aps, aucs, acc = [], [], []\n",
        "    for batch in inference_data.seq_batches(batch_size=200):\n",
        "        src, pos_dst, t, msg = batch.src, batch.dst, batch.t, batch.msg\n",
        "\n",
        "        neg_dst = torch.randint(min_dst_idx, max_dst_idx + 1, (src.size(0), ),\n",
        "                                dtype=torch.long, device=device)\n",
        "\n",
        "        n_id = torch.cat([src, pos_dst, neg_dst]).unique()\n",
        "        n_id, edge_index, e_id = neighbor_loader(n_id)\n",
        "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
        "\n",
        "\n",
        "        z, last_update = memory(n_id)\n",
        "        z = gnn(z, last_update, edge_index, data.t[e_id], data.msg[e_id])\n",
        "\n",
        "        z_global_pos = global_mem(z[assoc[src]], z[assoc[pos_dst]])\n",
        "        z_global_neg = global_mem(z[assoc[src]], z[assoc[neg_dst]])\n",
        " \n",
        "        pos_out = link_pred(z[assoc[src]], z[assoc[pos_dst]], z_global_pos)\n",
        "        neg_out = link_pred(z[assoc[src]], z[assoc[neg_dst]], z_global_neg)\n",
        "\n",
        "        y_pred = torch.cat([pos_out, neg_out], dim=0).sigmoid().cpu()\n",
        "        y_true = torch.cat(\n",
        "            [torch.ones(pos_out.size(0)),\n",
        "             torch.zeros(neg_out.size(0))], dim=0)\n",
        "\n",
        "        aps.append(average_precision_score(y_true, y_pred))\n",
        "        aucs.append(roc_auc_score(y_true, y_pred))\n",
        "        acc.append(accuracy_score(y_true, y_pred.round()))\n",
        "\n",
        "        memory.update_state(src, pos_dst, t, msg)\n",
        "        neighbor_loader.insert(src, pos_dst)\n",
        "        \n",
        "    return float(torch.tensor(aps).mean()), float(torch.tensor(aucs).mean()), float(torch.tensor(acc).mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjF3wwOb1wgH",
        "outputId": "cdcf6df4-27ee-486e-c786-29331e7eb65c"
      },
      "source": [
        "val_ap_list = []\n",
        "test_ap_list = []\n",
        "val_acc_list = []\n",
        "test_acc_list = []\n",
        "for epoch in range(1, 20):\n",
        "    loss = train()\n",
        "    print(f'  Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
        "    val_ap, val_auc, val_acc = test(val_data)\n",
        "    test_ap, test_auc, test_acc = test(test_data)\n",
        "    val_ap_list.append(val_ap)\n",
        "    test_ap_list.append(test_ap)\n",
        "    print(f' Val AP: {val_ap:.4f},  Val AUC: {val_auc:.4f}, Val Acc: {val_acc:.4f} ')\n",
        "    print(f'Test AP: {test_ap:.4f}, Test AUC: {test_auc:.4f}, Test Acc: {test_acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Epoch: 01, Loss: 1.3865\n",
            " Val AP: 0.5168,  Val AUC: 0.5097, Val Acc: 0.5063 \n",
            "Test AP: 0.5121, Test AUC: 0.5047, Test Acc: 0.5029\n",
            "  Epoch: 02, Loss: 1.3865\n",
            " Val AP: 0.5068,  Val AUC: 0.4991, Val Acc: 0.4976 \n",
            "Test AP: 0.5000, Test AUC: 0.4925, Test Acc: 0.4992\n",
            "  Epoch: 03, Loss: 1.3864\n",
            " Val AP: 0.5082,  Val AUC: 0.5012, Val Acc: 0.4947 \n",
            "Test AP: 0.5060, Test AUC: 0.4985, Test Acc: 0.4996\n",
            "  Epoch: 04, Loss: 1.3864\n",
            " Val AP: 0.5071,  Val AUC: 0.5001, Val Acc: 0.4967 \n",
            "Test AP: 0.5045, Test AUC: 0.4961, Test Acc: 0.4975\n",
            "  Epoch: 05, Loss: 1.3864\n",
            " Val AP: 0.5100,  Val AUC: 0.5019, Val Acc: 0.4967 \n",
            "Test AP: 0.5048, Test AUC: 0.4968, Test Acc: 0.4984\n",
            "  Epoch: 06, Loss: 1.3864\n",
            " Val AP: 0.5112,  Val AUC: 0.5029, Val Acc: 0.4969 \n",
            "Test AP: 0.5043, Test AUC: 0.4952, Test Acc: 0.4985\n",
            "  Epoch: 07, Loss: 1.3865\n",
            " Val AP: 0.5096,  Val AUC: 0.5042, Val Acc: 0.5011 \n",
            "Test AP: 0.5020, Test AUC: 0.4952, Test Acc: 0.4950\n",
            "  Epoch: 08, Loss: 1.3864\n",
            " Val AP: 0.5112,  Val AUC: 0.5045, Val Acc: 0.4981 \n",
            "Test AP: 0.5013, Test AUC: 0.4944, Test Acc: 0.4979\n",
            "  Epoch: 09, Loss: 1.3865\n",
            " Val AP: 0.5097,  Val AUC: 0.5030, Val Acc: 0.4979 \n",
            "Test AP: 0.5062, Test AUC: 0.4977, Test Acc: 0.4974\n",
            "  Epoch: 10, Loss: 1.3864\n",
            " Val AP: 0.5097,  Val AUC: 0.5023, Val Acc: 0.4982 \n",
            "Test AP: 0.5052, Test AUC: 0.4972, Test Acc: 0.4982\n",
            "  Epoch: 11, Loss: 1.3865\n",
            " Val AP: 0.5108,  Val AUC: 0.5054, Val Acc: 0.5002 \n",
            "Test AP: 0.5043, Test AUC: 0.4957, Test Acc: 0.4967\n",
            "  Epoch: 12, Loss: 1.3865\n",
            " Val AP: 0.5117,  Val AUC: 0.5051, Val Acc: 0.4996 \n",
            "Test AP: 0.5051, Test AUC: 0.4965, Test Acc: 0.4958\n",
            "  Epoch: 13, Loss: 1.3865\n",
            " Val AP: 0.5090,  Val AUC: 0.5024, Val Acc: 0.4994 \n",
            "Test AP: 0.5068, Test AUC: 0.4985, Test Acc: 0.4993\n",
            "  Epoch: 14, Loss: 1.3865\n",
            " Val AP: 0.5131,  Val AUC: 0.5063, Val Acc: 0.4999 \n",
            "Test AP: 0.5067, Test AUC: 0.4981, Test Acc: 0.4990\n",
            "  Epoch: 15, Loss: 1.3865\n",
            " Val AP: 0.5089,  Val AUC: 0.5006, Val Acc: 0.4973 \n",
            "Test AP: 0.5045, Test AUC: 0.4945, Test Acc: 0.4991\n",
            "  Epoch: 16, Loss: 1.3865\n",
            " Val AP: 0.5095,  Val AUC: 0.5015, Val Acc: 0.4973 \n",
            "Test AP: 0.5035, Test AUC: 0.4966, Test Acc: 0.4991\n",
            "  Epoch: 17, Loss: 1.3865\n",
            " Val AP: 0.5062,  Val AUC: 0.4990, Val Acc: 0.4975 \n",
            "Test AP: 0.5051, Test AUC: 0.4969, Test Acc: 0.4989\n",
            "  Epoch: 18, Loss: 1.3865\n",
            " Val AP: 0.5106,  Val AUC: 0.5052, Val Acc: 0.4969 \n",
            "Test AP: 0.5044, Test AUC: 0.4967, Test Acc: 0.4974\n",
            "  Epoch: 19, Loss: 1.3864\n",
            " Val AP: 0.5088,  Val AUC: 0.5033, Val Acc: 0.5007 \n",
            "Test AP: 0.5037, Test AUC: 0.4961, Test Acc: 0.4970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__hKwLjoZceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "5c7c7555-33b0-4db3-daf8-3cfc34c31084"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5, 3))\n",
        "axes[0].plot(val_ap_list)\n",
        "axes[1].plot(test_ap_list)\n",
        "axes[0].set_ylim([0, 1.1])\n",
        "plt.ylim(ymin=0, ymax=1.1)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADQCAYAAAA53LuNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAR20lEQVR4nO3dfWxd913H8ffnPtl5cJKmdrOSpEm1pRMBqq6yysTG1mkD0v7RgEBTI00MVC0gVoTEhFQE2kb5h4FgAqkMMjF1DK2lTBuLRFhBY2MD0VGHlq5plTXq2iZZ1jhNmifb9/HLH+fYuXHt+Nq+8e+Efl6SdR7uz/d8ff29n/u75+Y4igjMzGzllVIXYGb2ZuUANjNLxAFsZpaIA9jMLBEHsJlZIpVUBx4eHo7t27enOrxdgw4ePHgqIkZS1+HetcWar3eTBfD27dsZGxtLdXi7Bkl6OXUN4N61xZuvd30KwswsEQewmVkiDmAzs0QcwGZmiTiAzcwScQCbmSXiADYzS8QBbGaWiAPYzCwRB7CZWSIOYDOzRBYMYEmfk3RS0rPz3C5JfyHpiKRnJN3e/zLNFs+9a0XXywz4YWDXFW6/C9iRf+0FPrP8ssz64mHcu1ZgCwZwRHwLOH2FIbuBv43ME8AGSTf2q0CzpXLvWtH14xzwZuBo1/axfJ9Z0bl3LakV/RBO0l5JY5LGxsfHV/LQZsvi3rWroR8BfBzY2rW9Jd/3BhGxLyJGI2J0ZCT5f2xg5t61pPoRwPuBX84/UX4ncDYiTvThfs2uNveuJbXgf0kk6RHgTmBY0jHgE0AVICL+CjgA3A0cASaAX71axZothnvXim7BAI6IPQvcHsBH+1aRWZ+4d63ofCWcmVkiDmAzs0QcwGZmiTiAzcwScQCbmSXiADYzS8QBbGaWiAPYzCwRB7CZWSIOYDOzRBzAZmaJOIDNzBJxAJuZJeIANjNLxAFsZpaIA9jMLBEHsJlZIg5gM7NEHMBmZok4gM3MEnEAm5kl4gA2M0vEAWxmlogD2MwskZ4CWNIuSYclHZH0wBy33yTpG5KekvSMpLv7X6rZ4rl3rcgWDGBJZeAh4C5gJ7BH0s5Zw34feCwi3gHcC/xlvws1Wyz3rhVdLzPgO4AjEfFiRDSAR4Hds8YEsC5fXw/8oH8lmi2Ze9cKrZcA3gwc7do+lu/r9kngQ5KOAQeA35zrjiTtlTQmaWx8fHwJ5ZotinvXCq1fH8LtAR6OiC3A3cAXJL3hviNiX0SMRsToyMhInw5ttizuXUumlwA+Dmzt2t6S7+t2H/AYQET8FzAIDPejQLNlcO9aofUSwE8COyTdLKlG9kHF/lljXgHeDyDpR8ma2O/TLDX3rhXaggEcES3gfuBx4HmyT4wPSXpQ0j35sI8BH5H0v8AjwK9ERFytos164d61oqv0MigiDpB9QNG97+Nd688B7+pvaWbL5961IvOVcGZmiTiAzcwScQCbmSXiADYzS8QBbGaWiAPYzCwRB7CZWSIOYDOzRBzAZmaJOIDNzBJxAJuZJeIANjNLxAFsZpaIA9jMLBEHsJlZIg5gM7NEHMBmZok4gM3MEnEAm5kl4gA2M0vEAWxmlogD2MwsEQewmVkiPQWwpF2SDks6IumBecZ8UNJzkg5J+mJ/yzRbPPetFV1loQGSysBDwM8Ax4AnJe2PiOe6xuwAfhd4V0SckXTD1SrYrBfuW7sW9DIDvgM4EhEvRkQDeBTYPWvMR4CHIuIMQESc7G+ZZovmvrXC6yWANwNHu7aP5fu63QLcIuk/JT0haddcdyRpr6QxSWPj4+NLq9isN33rW3Dv2tXRrw/hKsAO4E5gD/BZSRtmD4qIfRExGhGjIyMjfTq02ZL11Lfg3rWro5cAPg5s7dreku/rdgzYHxHNiPg+8D2yxjZLxX1rhddLAD8J7JB0s6QacC+wf9aYfySbRSBpmOyt3Yt9rNNssdy3VngLBnBEtID7gceB54HHIuKQpAcl3ZMPexx4TdJzwDeA34mI165W0WYLcd/atUARkeTAo6OjMTY2luTYdm2SdDAiRlPX4d61xZqvd30lnJlZIg5gM7NEHMBmZok4gM3MEnEAm5kl4gA2M0ukUAF8drLJ1549wfj5eupSzMyuugX/HOVK+u/vn+bX/+5/ALhp42pGt13H7duuY3T7dey4YYhySX05TkQw2WxzdrLJ2ckmE402jVaHRqtDs50tG+0O9VYHgMFqmVXVMoPV0mXrJYmpZofJZpt6s81k/jXV7NBqdxiolhislBmslrP1/HtrlRLTP8nsf4UdAc325XVkdQWNVodWp5Mvg1Y729/qZMvBapl1gxWGBqusW1Vh3WCVdYNVhgYr1Fsdxs/XOXWhzvj5OuP58tSF7MVuZGiAkaEBbhgazNbXZttDgxU6EbQ6QbsdtCNod7KvksSG1VUGq+UFH/Nmu8OpC3VePVfnzMUGtUr2eKyuZV+rqmVW1cqsrlX69nteSV956hinzjf46VuGefumIaRr72ewlVeoAH7PLcN8+Td+ioMvneHgy2f41gun+PJT2eX7QwMVbt26nmq5RL3Zod7Kgu7SskO5BLVKiWq5RK1cmlmvlrOgPJcH7rmpJs12mgtQimRooMLw0AAA4+frXKi3lnQ/q6plNq6psWF1lY1raly3usaqapnxC3VePTfFq+fqvHaxTq/X/Pz5vbex+7bZf7is2L55eJyvPv0DOAA3DA3w7h3DvPeWEd71tmGG1w5cNvZivcUrpyd4+bUJXjl9kVMXGtTKJQbyF6WB6qX1ajl7k9qJIOLSMsiWJYlSSZQE5Xy9LFEuiVW1MmsHKqwdqLAmXw5WSz29OHQ6wamLdU68PsWJs1OcODvJD89OMdFoZ8+piqiVp59f0881USmVqJQ1sz69LJdEs92h3Qma+eQhm0QEzXaHqa4JTL3ZYbIxPZlpz9Q0XbYQUrY9WC1f9vOtqZVn1qef/1k9+XopW291OlluNNtM5RkylU+egqBSEuW8/nJJVEr5z1FWflv2OFfK2bjp+337W4YW1TeFvhIuIjh6epKDr5zm4Mtn+O6xswAMVKab9FKzDlTKdDrZL/PSrPHSzHGgWmLdqirr5/haXSvPBPZMgFeyEAdmfjHZL6rNZKPNVKtDp5PNOgerpXxWnM3iVlXLlEui3pr+pXZ9f6NNo9254s/d/eIxvRyoXGqkWt5U0w1eLWcNXm92ODeVvcCcm2xxfqrJuakW5yabDFRLjKwdYLhrdjt75jrRaGWz4/N1TubLC/XWTAOWu74qJdHqBK9PNDlzscHpiQavTzQ5fbHB6xMNJhpthtcOsGndAJvWDXLDusFsfWiQjWtrNFvZO4fJRpuJRpuJZvbYTDTa3PUTb+GWTW9s5KJfCXfi7CTffuEU337hFP/xwjhnJpoA/NiPrOOtI2s5dmaCV05PcOpC47LvG6iUaLY7dFbgqVguiTW1MrVK+bJwKZcu9dHZySavnpt6wySlVimxplam1Y7sOdbu9Pyi2qtaJXsuTb8jqpVLdL9eTL/4AHQCJhttLtRbXKy3aK3EA3gFawcqPPsHPzfnbfP1bqED2Kxb0QO4W7sTHPrBWb79win+/XvjHD8zydaNq9i2cQ03Xb+abdev5qaNq9m2cQ3rV1eB7DRNvTU9K8uWjXZnZsZXEkhCZDNfyGbEnXxmPH1qaPqU0VSjzfk8nC7WW13rbeqtDu1ONgtt5zPRVqdDqx0MDVa4ccMqblw/yI3rp5eDbFxTu2z2HPkxm3kgN9udmRnt7FNk7U7MzEZnZpN56FfKmpnALPX0U0RQb3W4WG8xkYdy9yQsq+nSeqUkBqrl/BRhiVW18szpwpKYmZ1P195s5z9rJ5t4zTxunZjZFvCBnZvmrG++3i3UKQiz/y/KJXHrlg3cumUDH33f23r6num3yWsHro2npfK34JUyrGLhzwGudi2DeYhfn7SSxSnUv4IwM3szcQCbmSXiADYzS8QBbGaWiAPYzCwRB7CZWSIOYDOzRBzAZmaJOIDNzBJxAJuZJeIANjNLpKcAlrRL0mFJRyQ9cIVxvygpJCX/gylm4N61YlswgCWVgYeAu4CdwB5JO+cYNwT8FvCdfhdpthTuXSu6XmbAdwBHIuLFiGgAjwK75xj3h8CngKk+1me2HO5dK7ReAngzcLRr+1i+b4ak24GtEfFPV7ojSXsljUkaGx8fX3SxZovk3rVCW/aHcJJKwJ8BH1tobETsi4jRiBgdGRlZ7qHNlsW9a6n1EsDHga1d21vyfdOGgB8HvinpJeCdwH5/mGEF4N61QuslgJ8Edki6WVINuBfYP31jRJyNiOGI2B4R24EngHsiwv/fkKXm3rVCWzCAI6IF3A88DjwPPBYRhyQ9KOmeq12g2VK5d63oevrPpyLiAHBg1r6PzzP2zuWXZdYf7l0rMl8JZ2aWiAPYzCwRB7CZWSIOYDOzRBzAZmaJOIDNzBJxAJuZJeIANjNLxAFsZpaIA9jMLBEHsJlZIg5gM7NEHMBmZok4gM3MEnEAm5kl4gA2M0vEAWxmlogD2MwsEQewmVkiDmAzs0QcwGZmiTiAzcwScQCbmSXSUwBL2iXpsKQjkh6Y4/bflvScpGckfV3Stv6XarY47lsrugUDWFIZeAi4C9gJ7JG0c9awp4DRiLgV+BLwx/0u1Gwx3Ld2LehlBnwHcCQiXoyIBvAosLt7QER8IyIm8s0ngC39LdNs0dy3Vni9BPBm4GjX9rF833zuA/55OUWZ9YH71gqv0s87k/QhYBR47zy37wX2Atx00039PLTZki3Ut/kY9671XS8z4OPA1q7tLfm+y0j6APB7wD0RUZ/rjiJiX0SMRsToyMjIUuo161Xf+hbcu3Z19BLATwI7JN0sqQbcC+zvHiDpHcBfkzXxyf6XabZo7lsrvAUDOCJawP3A48DzwGMRcUjSg5LuyYf9CbAW+AdJT0vaP8/dma0I961dC3o6BxwRB4ADs/Z9vGv9A32uy2zZ3LdWdL4SzswsEQewmVkiDmAzs0QcwGZmiTiAzcwScQCbmSXiADYzS8QBbGaWiAPYzCwRB7CZWSIOYDOzRBzAZmaJOIDNzBJxAJuZJeIANjNLxAFsZpaIA9jMLBEHsJlZIg5gM7NEHMBmZok4gM3MEnEAm5kl4gA2M0vEAWxmlkhPASxpl6TDko5IemCO2wck/X1++3ckbe93oWZL4d61IlswgCWVgYeAu4CdwB5JO2cNuw84ExFvAz4NfKrfhZotlnvXiq6XGfAdwJGIeDEiGsCjwO5ZY3YDn8/XvwS8X5L6V6bZkrh3rdAqPYzZDBzt2j4G/OR8YyKiJekscD1wqnuQpL3A3nzzgqTDcxxvePb3JeZ65rfStWxb5Hj3bnHqKVItUJDe7SWA+yYi9gH7rjRG0lhEjK5QSQtyPfMrUi1Xm3t3eYpUCxSnnl5OQRwHtnZtb8n3zTlGUgVYD7zWjwLNlsG9a4XWSwA/CeyQdLOkGnAvsH/WmP3Ah/P1XwL+LSKif2WaLYl71wptwVMQ+Xmx+4HHgTLwuYg4JOlBYCwi9gN/A3xB0hHgNFmjL9UV3+Yl4HrmV6Ra3sC9W6h6ilQLFKQe+cXezCwNXwlnZpaIA9jMLJFCBfBCl40mqOclSd+V9LSksRU+9ucknZT0bNe+jZL+VdIL+fK6xPV8UtLx/PF5WtLdK1VP0RSpd1P2bX58926PChPAPV42msL7IuK2BP9m8GFg16x9DwBfj4gdwNfz7ZT1AHw6f3xui4gDK1hPYRS0d1P1Lbh3e1aYAKa3y0bfNCLiW2Sfynfrvmz288DPJ67HMu7dLu7d3hUpgOe6bHRzolqmBfAvkg7ml6KmtikiTuTrPwQ2pSwmd7+kZ/K3eSv2trJgita7RetbcO/OqUgBXETvjojbyd5aflTSe1IXNC2/WCD1vyH8DPBW4DbgBPCnacuxXGH7Fty73YoUwL1cNrqiIuJ4vjwJfIXsrWZKr0q6ESBfnkxZTES8GhHtiOgAnyX945NKoXq3gH0L7t05FSmAe7lsdMVIWiNpaHod+Fng2St/11XXfdnsh4GvJqxl+ok07RdI//ikUpjeLWjfgnt3Tiv619CuZL7LRhOWtAn4Sv6nYSvAFyPiayt1cEmPAHcCw5KOAZ8A/gh4TNJ9wMvABxPXc6ek28jeTr4E/NpK1VMkBevdpH0L7t1F1eZLkc3M0ijSKQgzszcVB7CZWSIOYDOzRBzAZmaJOIDNzBJxAJuZJeIANjNL5P8A1C6YdurHG+UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W36ksC2G3LW1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5ce0173a-c9d6-4653-9f8c-8fe4b65e0ce1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(val_ap_list)\n",
        "plt.ylabel('some numbers')\n",
        "plt.ylim(ymin=0, ymax=1.1)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wSdcTNfYX2a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}